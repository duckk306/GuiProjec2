import streamlit as st
import joblib
import pandas as pd

from utils.nlp_cleandata import clean_text_fromdf, clean_text
from sklearn.metrics.pairwise import linear_kernel, cosine_similarity

st.header("‚≠ê G·ª£i √Ω xe m√°y t∆∞∆°ng t·ª±")
# ================== Feature lists ==================
num_cols = ['price', 'price_min', 'price_max', 'year_reg', 'km_driven', 'cc_numeric', 'price_segment_code', 'age']
flag_cols = ["is_moi", "is_do_xe", "is_su_dung_nhieu", "is_bao_duong", "is_do_ben", "is_phap_ly"]
cat_cols = ["brand", "vehicle_type", "model", "origin", "segment",'engine_size']

# Default brands fallback (in case user doesn't upload a dataset)
BRANDS = ['Aprilia','Bmw','Bazan','Benelli','Brixton','Cr&S','Daelim','Detech','Ducati','Gpx','Halim',
          'Harley Davidson','Honda','Hyosung','H√£ng Kh√°c','Ktm','Kawasaki','Keeway','Kengo','Kymco',
          'Moto Guzzi','Nioshima','Peugeot','Piaggio','Rebelusa','Royal Enfield','Sym','Sachs','Sanda',
          'Suzuki','Taya','Triumph','Vento','Victory','Vinfast','Visitor','Yamaha']

# ================== FUNCTIONS ==================     
@st.cache_resource 
def load_pipeline(suggest_model='model/cosine_sim_matrix.pkl',
                  tfidf='model/tfidf_vectorizer.pkl'):
    """
    Load cosine similarity matrix v√† vectorizer ƒë√£ l∆∞u tr∆∞·ªõc ƒë√≥.
    """
    cosine_matrix = joblib.load(suggest_model)
    vectorizer_loaded = joblib.load(tfidf)
    print("ƒê√£ load cosine matrix & vectorizer th√†nh c√¥ng.")
    return cosine_matrix, vectorizer_loaded

def recommend_by_id(data, item_id: int, top_n: int = 5):
    """
    Recommend similar motorbikes based on cosine similarity.
    Args:
        item_id (int): id ho·∫∑c index c·ªßa xe trong DataFrame
        top_n (int): s·ªë l∆∞·ª£ng g·ª£i √Ω mu·ªën l·∫•y
    Returns:
        DataFrame ch·ª©a c√°c xe t∆∞∆°ng t·ª±
    """
    if item_id not in data.index:
        raise ValueError(f"id {item_id} kh√¥ng t·ªìn t·∫°i trong c∆° s·ªü c·ªßa h·ªá th·ªëng")

    # L·∫•y h√†ng t∆∞∆°ng ·ª©ng trong ma tr·∫≠n cosine
    sim_scores = list(enumerate(cosine_sim_matrix[item_id]))

    # S·∫Øp x·∫øp theo ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·∫£m d·∫ßn, b·ªè ch√≠nh n√≥
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1: top_n + 1]

    # L·∫•y index xe t∆∞∆°ng t·ª±
    similar_indices = [i[0] for i in sim_scores]
    similar_scores = [i[1] for i in sim_scores]

    # T·∫°o DataFrame k·∫øt qu·∫£
    recommendations = data.loc[similar_indices, ['id', 'Ti√™u ƒë·ªÅ', 'Content']].copy()
    recommendations['similarity'] = similar_scores
    return recommendations.reset_index(drop=True)

def recommend_by_text(data, query: str, top_n: int = 5):
    """
    G·ª£i √Ω xe m√°y t∆∞∆°ng t·ª± d·ª±a tr√™n vƒÉn b·∫£n ng∆∞·ªùi d√πng nh·∫≠p v√†o.
    
    Args:
        query (str): vƒÉn b·∫£n t√¨m ki·∫øm
        top_n (int): s·ªë l∆∞·ª£ng g·ª£i √Ω
    
    Returns:
        DataFrame: danh s√°ch xe t∆∞∆°ng t·ª± + ƒë·ªô t∆∞∆°ng ƒë·ªìng
    """

    # 1. Ti·ªÅn x·ª≠ l√Ω query b·∫±ng h√†m clean_text c·ªßa b·∫°n
    clean_query = clean_text(query)

    # 2. Vector h√≥a query
    query_vec = tfidf.transform([clean_query])

    # 3. T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine gi·ªØa query v√† to√†n b·ªô item
    tfidf_matrix = tfidf.fit_transform(data['clean_text'])
    sims = cosine_similarity(query_vec, tfidf_matrix).flatten()

    # 4. L·∫•y top N k·∫øt qu·∫£ cao nh·∫•t
    top_idx = sims.argsort()[::-1][:top_n]
    top_scores = sims[top_idx]

    # 5. Tr·∫£ v·ªÅ DataFrame k·∫øt qu·∫£
    result = data.iloc[top_idx][['id', 'Ti√™u ƒë·ªÅ', 'Content']].copy()
    result["similarity"] = top_scores

    return result.reset_index(drop=True)


# ================== NAVIGATION ==================
st.sidebar.header("Navigation Menu")
st.sidebar.page_link("gui_project2.py", label="Home", icon="üè†")
st.sidebar.page_link("pages/intro.py", label="Gi·ªõi thi·ªáu", icon="üìÉ")
st.sidebar.page_link('pages/suggest_bikes.py', label='G·ª£i √Ω xe m√°y t∆∞∆°ng t·ª±', icon="‚≠ê")
st.sidebar.page_link('pages/predictprice_byclustering.py', label='D·ª± ƒëo√°n gi√° xe m√°y c≈©', icon="üíµ")
st.sidebar.page_link("pages/author.py", label="Th√¥ng tin t√°c gi·∫£", icon="‚ÑπÔ∏è")


# ================== LOAD PIPELINE ==================
cosine_sim_matrix, tfidf = load_pipeline(suggest_model='model/cosine_sim_matrix.pkl',
                            tfidf='model/tfidf_vectorizer.pkl')
data_cleaned = pd.read_csv("data_motobikes_CleanForRecommendation.csv", sep=",")

# ================== RECOMMENDATION FROM FILE ==================
st.subheader("A. Ch·ªçn th√¥ng tin xe quan t√¢m t·ª´ file")

uploaded_file = st.file_uploader("T·∫£i file Excel/CSV (data_motobikes.xlsx)", 
                                 type=["xlsx","csv"], key="pred_file")

if uploaded_file is not None:
    try:
        # 1. Read file
        if str(uploaded_file.name).lower().endswith(".csv"):
            data = pd.read_csv(uploaded_file)
        else:
            data = pd.read_excel(uploaded_file)
        st.success(f"Step 1. ƒê√£ ƒë·ªçc file: {uploaded_file.name} ‚Äî {data.shape[0]} h√†ng")
        st.dataframe(data.head(5))
        
        # 2. Filter interested bikes
        #    2.1. Prepare Dropdown options
        price = st.number_input("Gi√° mong mu·ªën (tri·ªáu VND)", min_value=0.0, value=10.0, step=0.1)
        price_min = st.number_input("Kho·∫£ng gi√° min (tri·ªáu VND)", min_value=0.0, value=8.0, step=0.1)
        price_max = st.number_input("Kho·∫£ng gi√° max (tri·ªáu VND)", min_value=0.0, value=12.0, step=0.1)
        
        last = st.session_state.get("last_clean")
        
        def options(feature, feature_list):
            opts = sorted(last[feature].dropna().unique().tolist()) if last is not None and feature in last.columns else feature_list
            return opts
        brands_opts = options("brand", BRANDS)
        models_opts = options("model", ["Wave","Exciter","Sirius"])
        vehicle_types_opts = options("vehicle_type", ["Xe s·ªë","Xe tay ga","Xe c√¥n"])
        origin_opts = options("origin", ["Vi·ªát Nam","Nh·∫≠p Kh·∫©u"])
        segment_opts = options("segment", ["Ph·ªï th√¥ng","C·∫≠n cao c·∫•p","Cao c·∫•p"])
        
        #     2.2. Prepare for inputs
        engine_size_sel = st.selectbox("Dung t√≠ch xe (nh√£n)", options=["D∆∞·ªõi 50","50 - 100","100 - 175","Tr√™n 175"], index=2)
        
        col1, col2 = st.columns(2)
        with col1:
            brand_inp = st.selectbox("Th∆∞∆°ng hi·ªáu (brand)", options=brands_opts)
            model_inp = st.selectbox("D√≤ng xe (model)", options=models_opts)
            vehicle_type_inp = st.selectbox("Lo·∫°i xe (vehicle_type)", options=vehicle_types_opts)
        with col2:
            km_driven = st.number_input("S·ªë Km ƒë√£ ƒëi (km_driven)", min_value=0, step=1, value=1000)
            cc_numeric = st.number_input("Dung t√≠ch numeric (cc_numeric)", min_value=0, step=1, value=137)
            age = st.number_input("Tu·ªïi xe (age)", min_value=0.1, step=0.1, value=3.0, format="%.1f")
        
        st.markdown("**T√¨nh tr·∫°ng (Tick = C√≥ / Kh√¥ng = Kh√¥ng)**")
        r1c1, r1c2, r1c3 = st.columns(3)
        with r1c1:
            is_moi = st.checkbox("is_moi", value=False)
        with r1c2:
            is_do_xe = st.checkbox("is_do_xe", value=False)
        with r1c3:
            is_su_dung_nhieu = st.checkbox("is_su_dung_nhieu", value=False)
        r2c1, r2c2, r2c3 = st.columns(3)
        with r2c1:
            is_bao_duong = st.checkbox("is_bao_duong", value=False)
        with r2c2:
            is_do_ben = st.checkbox("is_do_ben", value=False)
        with r2c3:
            is_phap_ly = st.checkbox("is_phap_ly", value=True)
            
        origin_inp = st.selectbox("Xu·∫•t x·ª© (origin)", options=origin_opts)
        segment_inp = st.selectbox("Ph√¢n kh√∫c (segment)", options=segment_opts)
        segment_map = {"Ph·ªï Th√¥ng": 1,
                        "T·∫ßm Trung": 2,
                        "Cao C·∫•p": 3}
        price_segment_code = segment_map.get(segment_inp, 1) 
        
        #   2.3. Filter
        if st.button("üîç L·ªçc xe quan t√¢m"):
            row = {
                "price": price,
                "price_min": price_min,
                "price_max": price_max,
                "km_driven": km_driven,
                "engine_size": engine_size_sel,
                "cc_numeric": cc_numeric,
                "age": age,
                "year_reg": 2025 - age,
                "price_segment_code": price_segment_code,
                "is_moi": int(is_moi),
                "is_do_xe": int(is_do_xe),
                "is_su_dung_nhieu": int(is_su_dung_nhieu),
                "is_bao_duong": int(is_bao_duong),
                "is_do_ben": int(is_do_ben),
                "is_phap_ly": int(is_phap_ly),
                "brand": brand_inp,
                "vehicle_type": vehicle_type_inp,
                "model": model_inp,
                "origin": origin_inp,
                "segment": segment_inp
            }
            
            df_filter = pd.DataFrame([row])
            st.dataframe(df_filter.head(10))
        

        # 3. Predict 
        if cosine_sim_matrix is None or tfidf is None:
            st.error("Model ho·∫∑c Vectorizer ch∆∞a ƒë∆∞·ª£c load (model_randomforest.pkl & tfidf_vectorizer.pkl).")
        else:
            try:
                sample_id = st.text_input("Nh·∫≠p 1 ID xe ƒë∆∞·ª£c g·ª£i √Ω ·ªü tr√™n")
                num_recommend = st.text_input("S·ªë xe g·ª£i √Ω ƒë∆∞·ª£c hi·ªÉn th·ªã", key="num_input_a")
                st.markdown("### Th√¥ng tin xe g·ªëc:")

                st.text("Ti√™u ƒë·ªÅ:" + data.loc[int(sample_id), "Ti√™u ƒë·ªÅ"])
                st.text("N·ªôi dung: " + data.loc[int(sample_id), "M√¥ t·∫£ chi ti·∫øt"])
                
                st.markdown("### G·ª£i √Ω c√°c xe t∆∞∆°ng t·ª±:")
                recommendation = recommend_by_id(data_cleaned, int(sample_id), top_n=int(num_recommend))
                recommendation_indicies = recommendation.index
                data_recomm = data[data.index.isin(recommendation_indicies)]
                
                overlapping_cols = recommendation.columns.intersection(data_recomm.columns)
                data_recomm_unique = data_recomm.drop(columns=overlapping_cols)
                merged_df = recommendation.join(data_recomm_unique, how='left')

                st.dataframe(merged_df)
                        
                
            except Exception as e:
                st.error(f"L·ªói khi d·ª± ƒëo√°n: {e}")
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc/ti·ªÅn x·ª≠ l√Ω file: {e}")


# ================== RECOMMENDATION FROM TEXT ==================
st.subheader("B. Ng∆∞·ªùi d√πng nh·∫≠p m√¥ t·∫£ xe quan t√¢m")
description = st.text_input("Nh·∫≠p m√¥ t·∫£ xe quan t√¢m")
st.markdown("*VD: xe c√≤n m·ªõi, m√°y √™m, hao xƒÉng √≠t, ƒë·ªùi t·ª´ 2019 tr·ªü l√™n. N·∫øu c√≥ Vision ho·∫∑c Janus ch·∫°y d∆∞·ªõi 10.000km th√¨ c√†ng t·ªët.*")
num_recommend2 = st.text_input("S·ªë xe g·ª£i √Ω ƒë∆∞·ª£c hi·ªÉn th·ªã", key="num_input_b")

data = pd.read_excel("data_motobikes.xlsx")
recommendation2 = recommend_by_text(data_cleaned, description, top_n=int(num_recommend2))
recommendation_indicies2 = recommendation2.index
data_recomm2 = data[data.index.isin(recommendation_indicies2)] 
overlapping_cols = recommendation2.columns.intersection(data_recomm2.columns)
data_recomm_unique = data_recomm2.drop(columns=overlapping_cols)
merged_df2 = recommendation2.join(data_recomm_unique, how='left')

st.dataframe(merged_df2)

